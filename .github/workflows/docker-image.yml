#  .github/workflows/docker-ci.yml
# prompt: Great progress! Here’s a clean, corrected, and ready-to-deploy version of your setup, incorporating:
# 	•	Your GitHub Actions Docker CI pipeline.
# 	•	Your JARIS graph-based prediction engine in Python.
# 	•	Fixes for logic bugs and formatting issues.
# ⸻
# 1. GitHub Actions Workflow (save as .github/workflows/docker-ci.yml):
# name: Docker Image CI
# on:
#   push:
#     branches: [ "main" ]
#   pull_request:
#     branches: [ "main" ]
# jobs:
#   build:
#     runs-on: ubuntu-latest
#     steps:
#     - uses: actions/checkout@v4
#     - name: Build the Docker image
#       run: docker build . --file Dockerfile --tag my-image-name:$(date +%s)
# ⸻
# 2. README.md — Add this snippet to explain usage:
# ## Symbolic Transition Graph
# This project models symbolic transitions as a directed graph for predictive analysis (JARIS engine).
# ### Features:
# - Cycle detection and weighting
# - Transition probability refinement
# - JARIS prediction generation
# - Dockerized CI with GitHub Actions
# To build locally:
# ```bash
# docker build -t symbolic-graph .
# ---
# ### 3. **`graph_model.py`** — Cleaned Python Core:
# ```python
# import networkx as nx
# from collections import defaultdict
# # Create and populate the graph with transitions and timestamps
# def create_transformation_graph(transitions):
#     G = nx.DiGraph()
#     for u, v, prob, timestamp in transitions:
#         G.add_edge(u, v, weight=prob, timestamp=timestamp)
#     return G
# # Identify all simple cycles
# def find_cycles(G):
#     return list(nx.simple_cycles(G))
# # Boost probabilities on cycles and normalize
# def refine_probabilities(G, cycles, multiplier=1.2):
#     for cycle in cycles:
#         for i in range(len(cycle)):
#             u, v = cycle[i], cycle[(i + 1) % len(cycle)]
#             if G.has_edge(u, v):
#                 G[u][v]['weight'] *= multiplier
#     normalize_probabilities(G)
# # Normalize outgoing edge weights from each node
# def normalize_probabilities(G):
#     for node in G.nodes:
#         out_edges = list(G.out_edges(node, data=True))
#         total = sum(data['we

import networkx as nx
from collections import defaultdict

# Create and populate the graph with transitions and timestamps
def create_transformation_graph(transitions):
    G = nx.DiGraph()
    for u, v, prob, timestamp in transitions:
        G.add_edge(u, v, weight=prob, timestamp=timestamp)
    return G

# Identify all simple cycles
def find_cycles(G):
    return list(nx.simple_cycles(G))

# Boost probabilities on cycles and normalize
def refine_probabilities(G, cycles, multiplier=1.2):
    for cycle in cycles:
        for i in range(len(cycle)):
            u, v = cycle[i], cycle[(i + 1) % len(cycle)]
            if G.has_edge(u, v):
                G[u][v]['weight'] *= multiplier
    normalize_probabilities(G)

# Normalize outgoing edge weights from each node
def normalize_probabilities(G):
    for node in G.nodes:
        out_edges = list(G.out_edges(node, data=True))
        total = sum(data['weight'] for _, _, data in out_edges)
        if total > 0:  # Avoid division by zero
          for u, v, data in out_edges:
              data['weight'] /= total
